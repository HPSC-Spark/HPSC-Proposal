\documentclass{article}
\usepackage{natbib}

%%%
%
% I wrote outline in the comments below to helpfully guide us
% but obviously feel free to modify/stray from it as you see fit
%
%%%

\title{High-Performance Data Analysis on Janus using Apache Spark}
\author{Nick Vanderweit \\
        Ning Gao \\
        Anitha Ganesha \\
        Michael Kasper}

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\section*{Introduction}
MapReduce\citep{dean-mapreduce} is a programming paradigm for performing highly
parallel tasks on large sets of data. Designed at Google to provide an
abstraction for interacting with raw data at scale, MapReduce is based on
a master/slave model, where the workers are assigned tasks as they become idle.

MapReduce is named after the two kinds of tasks that workers can be assigned.
A \emph{Map} is a user-defined function of type
$(k_1 \times v_1) \rightarrow list \: (k_2 \times v_2)$.
That is, it takes a key-value pair and produces a list of
intermediate key-value pairs. \emph{Reduce} has type
$(k_1 \times list \: v_1) \rightarrow list \: v_2$.\footnote{
These tasks are inspired by the \emph{map} and \emph{fold}
higher-order functions from functional programming.}
Reduce tasks are responsible for distilling a set of values associated with
a key to a smaller set, often containing just one value.

Despite its popularity, the MapReduce architecture has some significant
limitations. For one, Reduce tasks can only be assigned after all Map tasks
have been completed, meaning that nodes will idle even when there is work
remaining. Another major performance limitation, which will be central to the
motivation behind this project, is the architecture's reliance on a distributed
filesystem. This limits the performance of iterative computations because every
Map or Reduce task needs to read its input from storage and write its output
back.

% what is map-reduce, history, applications (1 Ref Paper) 
%   - origin, date, creators, original purpose
%   - growing popularity, expanding applications
%   - common technologies/tools, Hadoop
% Janus description, why Janus can't use Hadoop (1 Ref Paper) 
%       \citep{tufo}
%   - what, where is it
%   - architecture, hardware: number of nodes, procs, storage
%   - focus on disk-less, common for HPC?
%   - has not yet employed MR technologies
%   - problem with Hadoop and disk-less
% what is spark, differs from Hadoop 
% Spark\citep{zaharia}
%   - relationship with Scala (statically typed HL programming language for JVM)
%       \citep{zaharia}
%   - spark another MR solution, but all in-memory, year created
%   - solves the disk-less problem, can run on Janus
%   - other contrasts with Hadoop, preferred domains
%         - iterative, interactive, beyond MapReduce

%   - what is shark (do we want to use Shark in our project?)
%       - shark comes with its own set of benchmark queries

% Provides easy SQL programming interface to Spark's deep analysis tools.
% Shark\citep{engle}

\section*{Existing Performance Evaluations }
Despite being a relatively new technology, a considerable amount of performance
evaluations has been performed on the wide array of MapReduce solutions.
In Google's first paper introduction MapReduce, they provided a number of
example tasks in which MapReduce can be applied. A few of those listed were
word count, distributed grep, counting URL access frequency, \& reverse web-link
graph\citep{dean-mapreduce}. These examples have often been implemented for
benchmarking other MapReduce technologies and gives us a initial point in which
to start our evaluation of Spark on Janus.

%% Assuming Hadoop reference above
Hadoop, being is one of the more popular MapReduce frameworks, has been in a
number of different studies. For this reason (and its large contrast in how
it utilizes memory and disk storage), Hadoop will make for an interesting
comparison with Spark.

% performance of mapreduce: an in-depth study
% written in Java
% Hadoop\citep{jiang}


As Spark is a newer technologies, it does not have the same quantity of
performance evaluations as Hadoop. But there still has been a significant
amount of conducted research on Spark (and the related Shark) that will gives
some initial insight and its performance that will aid us in our research.

% outperforms Hadoop by 10x in iterative machine learning jobs
% queries 39GB dataset with sub-second response time
% \citep{zaharia}

% Resilient Distributed Datasets (RDDs)
%     read only collection of objects
%     partitioned across a set of machines
%     data need not exist in physical storage

% Parallel Operations on these datasets
% \citep{zaharia}


%               "Performance and Scalability of Broadcast in Spark"
%               determined broadcast limited scalability
%               compares performance of Spark vs Hadoop on Logistic Reg prob
%               times during first and second iterations
%               ratio: computation vs broadcast times during an iteration
% Broadcast\citep{chowdhury}
% load into memory, read only happens once, overhead of creating workers reduce

As we will be running Spark with Shark, we will also briefly touch on the
reported performance of Shark. When compared to Hive (Hadoop's respective
SQL interface) we see that the run-times for the first iteration are comparable,
(when data need to be loaded into memory). But Shark is shown to be 10 orders
of magnitude faster during subsequent iterations of an algorithms\citep{engle}.
Even if this is not a pure comparison of the Hadoop and Spark technologies, we
can still glean some additional insights as to where each technology performs
best.


% introduction to shark
%   SQL interface for spark
%   abstracts coding mapreduce functions
%   - shark study results
% Shark\citep{engle}

\section*{Proposal}
% room for further research
%   - what are questions we can still try to answer
%   - how does Janus make this a special case
%       - make very Janus specific

\subsection*{Setup/Profiling}
% do same grep test as google & Hadoop

% profile performance of spark on Janus 
% existing technologies for MR
% possibility of adapting these benchmarks to run on Janus
% find/address weak points/Janus-specific problems 
% possible areas to focus on during evaluation:
%   - too big for memory (benchmarking on this specific problem) 
%   - data shuffling work 
%   - network congestion 
%   - iterative, interactive analysis
%   - load balancing
%   - fault tolerance
% create models that can be used both others in the future
%   - guide for what hardware requirements are needed for given problems

\subsection*{Implementing Project X}

% time-permitting, employ spark on a project
% brief intro to topic/problem (1-2 Ref Paper) 
% how does it lend itself to MapReduce (Spark) approach
% overview of design/implementation
% profile program and improve performance 
% using insight gained from phase one profiling
% model for future MR applications on Janus

%%% current ideas (input still needed):
%%% - Ray-tracing
%%% - NLP of Twitter (or similar) Data
%%% - Neural Networks

\section*{Process/Schedule}
% Monte is our sponsor/advisor
% expected time-line/milestone dates
%   - install, play, understand
%   - device test problems, collect data
%   - find-setup / develop metrics
%   - run test and varying problems sets
%   - analyze results
% reiterate "project implementation" will be approach if time allows
%   - general milestones

\section*{Conclusion}

% sum up MR's importance
% setup on Janus, test, evaluate
% path for research to be conducted in future
% restate project goals
% specific conditions of Janus
% add info to relatively new field

\bibliography{paper}
\bibliographystyle{plain}

\end{document}
